import numpy as np
import cv2
from random import randint
from keras.models import load_model
import load_images
import filtFuncs as f                                                         
import time

# load model
model = load_model("car_model.h5")
# load video
cap = cv2.VideoCapture('../road.mp4')

# Set number of particles
nPart = 200
# Points that the particle images will be normalized to
pts2 = np.float32([[0,0],[63,0],[0,63],[63,63]])

# Capture first frame                                                               \
                                                                                         
ret, frame = cap.read()
# Our operations on the frame come here                                                                                                                                          
height, width, channels = frame.shape


#extra_area determines how large of a square we will have around the particle, and extra_area of 100 would make a 200 by 200 square
extra_area = 30
# generate x, y coordinates for the particles                                           
y = [randint(extra_area,(height-extra_area)) for p in range(nPart)]
x = [randint(extra_area,(width-extra_area)) for p in range(nPart)]


#R is the amount of noise in the predict step
R = 4

#frame_skip is the number of frames we skip in the beginning
frame_index = 0
frame_skip = 100

while(True):
    frame_index += 1
    # Capture frame-by-frame                                                                                       
    ret, frame = cap.read()
    if frame_index < frame_skip:
        continue

    # Our operations on the frame come here
    
    #convert image to gray scale
    gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    weights =[]
    windows = np.zeros((nPart, 64, 64, 1))
    
    for i in range(nPart):
        #calucalte the coordinates of a square with the particle at the center
        
        xl = x[i]-extra_area
        xr = x[i]+extra_area
        yd = y[i]-extra_area
        yu = y[i]+extra_area
        
        #transform this square to 64x64
        pts1 = np.float32([[xl,yd],[xr,yd],[xl,yu],[xr,yu]])
        M = cv2.getPerspectiveTransform(pts1,pts2)
        dst = cv2.warpPerspective(gray_image,M,(64,64))
        
        # Store the current window
        windows[i, :, :, :] = dst.reshape((64, 64, 1))

        #calculate the weights, I don't think this is right
        #scale = model.predict_proba(dst.reshape((1,64,64,1)))
        #weights.append(scale)

        # do not know why x and y are switched but it seems like they are in
        # the right places in the video
        cv2.circle(frame,(int(x[i]),int(y[i])), 2, (0,0,255), -1)

    # Calculate all weights in one go
    weights = model.predict_proba(windows)
    
    print weights
    
    # Display the resulting frame
    cv2.imshow('window',windows[0,:,:,:])
    cv2.imshow('frame',frame)
    #cv2.imshow('frame',windows[nPart-1, :, :, :])
    #normalize the weights
    weights = weights / sum(weights)
    #resample
    sampleInds = f.systematic_resample(weights)
    
    #update particles
    x = [x[i] for i in sampleInds]
    y = [y[i] for i in sampleInds]
    
    #predict step, only movement now is noise
    x,y = f.predict(x,y,R)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# When everything done, release the capture                                                                        
cap.release()
cv2.destroyAllWindows()
